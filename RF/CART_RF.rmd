---
title: "CART_RF"
output: html_document
---

# CART & Random Forest
```{r}
install.packages("yardstick")
set.seed(67)
```


```{r setup, include=FALSE}
library(mlbench)
library(rpart)
library(rattle)
library(yardstick)
library(randomForest)
library(xtable)
data("Ionosphere")
```
According to the documentation, this data set include "[...] radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. [...] The targets were free electrons in the ionosphere. "good" radar returns are those showing evidence of some type of structure in the ionosphere. "bad" returns are those that do not; their signals pass through the ionosphere." [source](https://www.rdocumentation.org/packages/mlbench/versions/2.1-3/topics/Ionosphere).

## EDA
```{r}
summary(Ionosphere)
```
Based on the "V" variables predictors representing values of the measured electromagnetic field (with both real and complex components), we'll build a classification and then a Random Forest model in order to predict the *Class* variable about whether a measure is "good" or "bad" (refer to the above description for an interpretation of those categories).

From the initial exploration, we can see that the dataset contains almost twice observations having "class"=good as observation having "class"=bad. Therefore, we'll have to be careful of this characteristic When drawing conclusions about our models.

```{r}
myblue <- rgb(0, 0, 255, max = 255, alpha = 125, names = "blue50")
myred <- rgb(255, 0, 0, max = 255, alpha = 125, names = "red50")
hist(Ionosphere$V3, col=myblue, alpha=125)
hist(Ionosphere$V4, col=myred, alpha=125, add=TRUE)
```


## Dataset preparation
a) To build our model, we'll do a random 80/20 train/test split on our dataset. Because we want to keep the same "good"/"bad" distribution in test and train datasets as in the initial one, we will use the createDataPartition method from the caret package to do so:
```{r}
library(caret)

set.seed(67)
train_samples <- Ionosphere$Class %>% # return the indexes of the rows
      createDataPartition(p = 0.8, list = FALSE)

Ionosphere.train <- Ionosphere[train_samples, ]
Ionosphere.test <- Ionosphere[-train_samples, ]

split_stats = rbind(summary(Ionosphere$Class)/nrow(Ionosphere)*100, summary(Ionosphere.train$Class)/nrow(Ionosphere.train)*100, summary(Ionosphere.test$Class)/nrow(Ionosphere.test)*100)

print(split_stats)

print(xtable(split_stats, type="latex"), file="split_stats.tex")
```
The table of the distribution ensures us that the data is well represented in both sets.


## Classification tree
### First iteration
As our first model, we will apply a simple classification tree on the training data then we'll see how it performs and the test set.
```{r, echo=FALSE}
# To get variables names to sum
for(v in colnames(Ionosphere)[-35]){cat(paste(v,"+ "))}
```

```{r}
#Ionosphere.tree.train = rpart(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, method="class")
```

We will use different CP values and plot the classification trees in order to study its influence on the computed tree:
```{r}
Ionosphere.tree.train = rpart(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, method="class", cp=0.3)

fancyRpartPlot(Ionosphere.tree.train)
```
```{r}
Ionosphere.tree.train = rpart(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, method="class", cp=0.2)

fancyRpartPlot(Ionosphere.tree.train)
```
```{r}
Ionosphere.tree.train = rpart(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, method="class", cp=0.1)

fancyRpartPlot(Ionosphere.tree.train)
```
```{r}
Ionosphere.tree.train = rpart(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, method="class", cp=0.005)

fancyRpartPlot(Ionosphere.tree.train)
```


**Answer b)** Here is the classification tree for a default run:
```{r}
Ionosphere.tree.train = rpart(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, method="class")

fancyRpartPlot(Ionosphere.tree.train, main="Default parameter run")
```
```{r}
Ionosphere.tree.train
```


Let's describe the obtained classification tree. We got 5 splits and 6 leaves.
Although having 34 variables to predict the "class" variable, only 5 (V5, V27, V8, V22 and V3) are selected for this classification tree.


### Performance test
Now, we can apply this classification tree to the test dataset and conclude about its performances.
```{r}
pred = predict(Ionosphere.tree.train, Ionosphere.test, type="class")
before_cp_a <- mean(pred==Ionosphere.test$Class)
before_cp_a
```
With a (simple) accuracy score, we have 0.87% of correct predictions on the tests, which is not bad for a first iteration.

**Answer d)** Therefore, we have misclassified observations which can also be seen under a confusion matrix:
```{r}
table(pred=pred, true=Ionosphere.test$Class)
```
But as we said before, there is a consequent disparity in the repartition of "good"/"bad" observation. To complete our simple accuracy score, we'll compute the balanced accuracy score, which takes into account the repartition of the data.
```{r}
before_cp_ba <- bal_accuracy_vec(pred, truth=Ionosphere.test$Class, estimator="binary")
before_cp_ba
```
The balanced accuracy being lower than the simple accuracy mean that the least represented class (which is "bad" here) is having a stronger weight (in fact, as weighted as the other class) in the accuracy score. 

Thus, we can deduce that predictions are better on class="good" observation than class="bad". 

Finally, we can confirm this conclusion with the confusion matrix showing that only 3 observations were misclassified as good (when supposed to be bad) when 6 observations, **twice more**, were misclassified as bad (when supposed to be good).

### Improving our classification tree with pruning
Before moving forward to the random forest, could we improve our classification tree using pruning ?

```{r}
plotcp(Ionosphere.tree.train, main="Error related to CP values")
```

To so, we'll acquire the complexity parameter (CP) leading to the lowest error:
```{r}
min_iono <- which.min(Ionosphere.tree.train$cptable[, "xerror"])
opt_cp <- Ionosphere.tree.train$cptable[min_iono, "CP"]
opt_cp
```
Which is corresponding to a CP value of 3 when our initial classification tree includes 5 splits instead of 3. Let's recompute the classification tree using this CP parameter and compute the accuracy score:
```{r}
Ionosphere.tree.train = rpart(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, method="class", cp=opt_cp)
pred = predict(Ionosphere.tree.train, Ionosphere.test, type="class")
after_cp_a <- mean(pred==Ionosphere.test$Class)
after_cp_a
```
and the balanced accuracy:
```{r}
after_cp_ba <- bal_accuracy_vec(pred, truth=Ionosphere.test$Class, estimator="binary")
after_cp_ba
```
Which are both better than before.

```{r}
cfm = confusionMatrix(pred, reference=Ionosphere.test$Class)
cfm
print(xtable(cfm$table, type="latex"), file="confusion_matrix.tex")
```

```{r}
fancyRpartPlot(Ionosphere.tree.train)
```


## Random forest
### Default parameters
Now we will compute a random forest in the hope for a better accuracy score, using the `randomForest` library:
```{r}
rf = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train)
print(rf)
```

```{r}
pred = predict(rf, Ionosphere.test, type="class")
table(pred=pred, true=Ionosphere.test$Class)
```

```{r}
paste(mean(pred==Ionosphere.test$Class), bal_accuracy_vec(pred, truth=Ionosphere.test$Class, estimator="binary"))
```


### Optimal number of variables
We will try to find the optimal number of variable used in our trees. To do so, we will iterate over a range of variable number and plot the OOB error rate.
```{r}
oob_per_mtry <- function(mtry){
  model = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, ntree=500, mtry=mtry)
  
  return(model$err.rate[498,1])
}

mtry_vals = c(1:34)
oob_vals = lapply(mtry_vals, oob_per_mtry)
plot(mtry_vals, oob_vals)
```

On the above plot we can see that the OOB error seems to be reaching a global minimum around 7 variables. However, we have to take into consideration that those result we obtained one set of train/test split and parameters may differ for different simulations.

We'll then recompute our Random Forest model with this *mtry* paramter:
```{r}
model = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, ntree=500, mtry=10)
print(rf)
```

```{r}
pred = predict(rf, Ionosphere.test, type="class")
table(pred=pred, true=Ionosphere.test$Class)
paste(mean(pred==Ionosphere.test$Class), bal_accuracy_vec(pred, truth=Ionosphere.test$Class, estimator="binary"))
```


### Tree numbers
```{r}
plot(rf, main="Random forest")
```

We can see that our error rates seems lower around 130. We will generate a new Random Forest model:
```{r}
rf = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, ntree=130)
rf
plot(rf)
```


We then use this Random Forest to predict the test data:
```{r}
pred = predict(rf, Ionosphere.test, type="class")
table(pred=pred, true=Ionosphere.test$Class)
```
We still have a more "good" values that were supposed to be classified as "bad" than the contrary but we have a way better accuracy (whether it is simple or balanced):
```{r}
paste(mean(pred==Ionosphere.test$Class), bal_accuracy_vec(pred, truth=Ionosphere.test$Class, estimator="binary"))
```

## Going further with this model with feature engineering
From a purely physical point of view, we could also take into account the norm of the electromagnetic field into consideration to state whether a signal is "good" or "bad". Therefore, we'll add the norm of each couple of measurement (real and complex values) and study its influence on the Random Forest performances.

```{r}
v_names = colnames(Ionosphere)[3:34]
norms_list <- vector(mode = "list", length = 16)

for(i in 1:(length(v_names)/2)){
  #Ionosphere[v_names[i]] = as.numeric(Ionosphere[v_names[i]])
  #Ionosphere[v_names[i+1]] = as.numeric(Ionosphere[v_names[i+1]])
  
  # To compute the squared norm
  print(paste(i, v_names[2*i - 1], v_names[2*i]))
  norms_list[i] = (Ionosphere[v_names[2*i]])**2 + (Ionosphere[v_names[2*i-1]])**2
}

Ionosphere.with_norms = cbind(Ionosphere, norms_list)

colnames(Ionosphere.with_norms) <- append(colnames(Ionosphere), c("N1", "N2", "N3", "N4", "N5", "N6", "N7", "N8", "N9", "N10", "N11", "N12", "N13", "N14", "N15", "N16"))
```

We reapply the train/test separation:
```{r}
library(caret)

train_samples <- Ionosphere.with_norms$Class %>% # return the indexes of the rows
      createDataPartition(p = 0.8, list = FALSE)

Ionosphere.with_norms.train <- Ionosphere.with_norms[train_samples, ]
Ionosphere.with_norms.test <- Ionosphere.with_norms[-train_samples, ]

split_stats = rbind(summary(Ionosphere.with_norms$Class)/nrow(Ionosphere.with_norms)*100, summary(Ionosphere.with_norms.train$Class)/nrow(Ionosphere.with_norms.train)*100, summary(Ionosphere.with_norms.test$Class)/nrow(Ionosphere.with_norms.test)*100)

print(split_stats)
```
Then compute a new randomForest:

```{r}
# To get variables names to sum
for(v in colnames(Ionosphere.with_norms)[-35]){cat(paste(v,"+ "))}
```
```{r}
model_with_norm = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34 + N1 + N2 + N3 + N4 + N5 + N6 + N7 + N8 + N9 + N10 + N11 + N12 + N13 + N14 + N15 + N16, data = Ionosphere.with_norms.train)
plot(model_with_norm)
model_with_norm
```

Performances:
```{r}
pred = predict(model_with_norm, Ionosphere.with_norms.test, type="class")
table(pred=pred, true=Ionosphere.with_norms.test$Class)
```

```{r}
paste(mean(pred==Ionosphere.with_norms.test$Class), bal_accuracy_vec(pred, truth=Ionosphere.with_norms.test$Class, estimator="binary"))
```


### Number of variables
```{r}
oob_per_mtry <- function(mtry){
  model = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34, data = Ionosphere.train, ntree=500, mtry=mtry)
  
  return(model$err.rate[498,1])
}

mtry_vals = c(1:34)
oob_vals = lapply(mtry_vals, oob_per_mtry)
plot(mtry_vals, oob_vals)
```
Seems to be optimal for mtry=6

```{r}
model_with_norm = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34 + N1 + N2 + N3 + N4 + N5 + N6 + N7 + N8 + N9 + N10 + N11 + N12 + N13 + N14 + N15 + N16, data = Ionosphere.with_norms.train, mtry=6)
model_with_norm
```

Performances:
```{r}
pred = predict(model_with_norm, Ionosphere.with_norms.test, type="class")
table(pred=pred, true=Ionosphere.with_norms.test$Class)
```

```{r}
paste(mean(pred==Ionosphere.with_norms.test$Class), bal_accuracy_vec(pred, truth=Ionosphere.with_norms.test$Class, estimator="binary"))
```

### Number of trees
```{r}
model_with_norm = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34 + N1 + N2 + N3 + N4 + N5 + N6 + N7 + N8 + N9 + N10 + N11 + N12 + N13 + N14 + N15 + N16, data = Ionosphere.with_norms.train, mtry=6, ntree=1000)
plot(model_with_norm)
model_with_norm
```

Minimal error seems around 300, we'll recompute to zoom in
```{r}
model_with_norm = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34 + N1 + N2 + N3 + N4 + N5 + N6 + N7 + N8 + N9 + N10 + N11 + N12 + N13 + N14 + N15 + N16, data = Ionosphere.with_norms.train, mtry=6, ntree=500)
plot(model_with_norm)
model_with_norm
```
Seems optimal for ntrees=100:
```{r}
model_with_norm = randomForest(formula = Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32 + V33 + V34 + N1 + N2 + N3 + N4 + N5 + N6 + N7 + N8 + N9 + N10 + N11 + N12 + N13 + N14 + N15 + N16, data = Ionosphere.with_norms.train, mtry=6, ntree=100)
```


Performances:
```{r}
pred = predict(model_with_norm, Ionosphere.with_norms.test, type="class")
table(pred=pred, true=Ionosphere.with_norms.test$Class)
```

```{r}
paste(mean(pred==Ionosphere.with_norms.test$Class), bal_accuracy_vec(pred, truth=Ionosphere.with_norms.test$Class, estimator="binary"))
```

Important features
```{r}
model_with_norm$importance
```


